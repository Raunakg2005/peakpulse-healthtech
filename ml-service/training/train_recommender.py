"""
Train Challenge Recommender Model
Creates a real ML-based recommendation system using user-challenge interactions
"""
import pandas as pd
import numpy as np
import joblib
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import GradientBoostingClassifier
import os

print("="*70)
print("üéØ TRAINING CHALLENGE RECOMMENDER MODEL")
print("="*70)

# Load data
print("\n1Ô∏è‚É£ Loading user and challenge data...")
features_df = pd.read_csv('data/features.csv')
challenges_df = pd.read_csv('data/challenges.csv')

print(f"   Users: {len(features_df)}")
print(f"   Challenge records: {len(challenges_df)}")

# Create user-challenge interaction dataset
print("\n2Ô∏è‚É£ Creating user-challenge interaction matrix...")

# Define challenge types with difficulties
challenge_types = [
    {"id": "C001", "name": "Morning Meditation", "category": "meditation", "difficulty": 2},
    {"id": "C002", "name": "10K Steps Challenge", "category": "exercise", "difficulty": 3},
    {"id": "C003", "name": "Hydration Hero", "category": "water", "difficulty": 1},
    {"id": "C004", "name": "Evening Yoga", "category": "exercise", "difficulty": 2},
    {"id": "C005", "name": "Mindful Eating", "category": "meals", "difficulty": 4},
    {"id": "C006", "name": "Sleep Sanctuary", "category": "sleep", "difficulty": 3},
    {"id": "C007", "name": "7-Day Streak", "category": "exercise", "difficulty": 5},
    {"id": "C008", "name": "Breathwork", "category": "meditation", "difficulty": 1},
]

# Create training data from actual challenge completion
training_data = []

for _, user in features_df.iterrows():
    user_id = user['user_id']
    user_challenges = challenges_df[challenges_df['user_id'] == user_id]
    
    # For each challenge type, create a training sample
    for challenge in challenge_types:
        # Check if user attempted this challenge category
        category_attempts = user_challenges[user_challenges['category'] == challenge['category']]
        
        if len(category_attempts) > 0:
            # User attempted this category
            completion_rate = category_attempts['completed'].mean()
            completed = 1 if completion_rate > 0.5 else 0  # Label
        else:
            # User didn't attempt - predict based on features
            # Create synthetic label based on user profile
            completion_rate = 0
            
            # Predict if user would like this challenge
            if challenge['difficulty'] <= 2:
                # Easy challenges - base on engagement
                completed = 1 if user.get('challenge_completion_rate', 0) > 0.3 else 0
            elif challenge['difficulty'] <= 3:
                # Medium challenges
                completed = 1 if user.get('challenge_completion_rate', 0) > 0.5 else 0
            else:
                # Hard challenges - only for high performers
                completed = 1 if user.get('challenge_completion_rate', 0) > 0.7 else 0
        
        # Create feature vector
        training_data.append({
            'user_id': user_id,
            'challenge_id': challenge['id'],
            'challenge_difficulty': challenge['difficulty'],
            # User features
            'days_active': user.get('days_active', 0),
            'avg_steps': user.get('avg_steps_last_7_days', 0),
            'meditation_streak': user.get('meditation_streak', 0) if 'meditation_streak' in user else user.get('avg_meditation_minutes', 0),
            'avg_sleep': user.get('avg_sleep_hours', 7),
            'challenge_completion_rate': user.get('challenge_completion_rate', 0),
            'social_score': user.get('social_engagement_score', 0),
            # Target
            'will_complete': completed
        })

training_df = pd.DataFrame(training_data)
print(f"   Created {len(training_df)} user-challenge pairs")
print(f"   Positive samples: {training_df['will_complete'].sum()} ({training_df['will_complete'].mean():.1%})")

# Prepare features with enhanced engineering
print("\n3Ô∏è‚É£ Preparing features with enhanced engineering...")

# Add interaction features
training_df['difficulty_completion_interaction'] = (
    training_df['challenge_difficulty'] * training_df['challenge_completion_rate']
)
training_df['steps_social_interaction'] = (
    training_df['avg_steps'] / 10000 * training_df['social_score']
)
training_df['active_ratio'] = (
    training_df['days_active'] / (training_df['meditation_streak'] + 1)
)

feature_cols = [
    'challenge_difficulty',
    'days_active',
    'avg_steps',
    'meditation_streak',
    'avg_sleep',
    'challenge_completion_rate',
    'social_score',
    # New engineered features
    'difficulty_completion_interaction',
    'steps_social_interaction',
    'active_ratio'
]

X = training_df[feature_cols].values
y = training_df['will_complete'].values

print(f"   Feature matrix: {X.shape}")
print(f"   Target distribution: {np.bincount(y)}")

# Split data
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

print(f"   Train: {len(X_train)}, Test: {len(X_test)}")

# Train optimized models
print("\n4Ô∏è‚É£ Training optimized models...")
print("   Testing Random Forest and Gradient Boosting...")

best_model = None
best_score = 0
best_name = ""

# Random Forest configurations
rf_configs = [
    {'n_estimators': 150, 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 4},
    {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 3},
]

# Gradient Boosting configurations
gb_configs = [
    {'n_estimators': 150, 'learning_rate': 0.1, 'max_depth': 5},
    {'n_estimators': 200, 'learning_rate': 0.05, 'max_depth': 6},
    {'n_estimators': 250, 'learning_rate': 0.08, 'max_depth': 4},
]

# Try Random Forest
print("\n   Random Forest:")
for i, config in enumerate(rf_configs, 1):
    model = RandomForestClassifier(
        class_weight='balanced',
        random_state=42,
        n_jobs=-1,
        **config
    )
    
    model.fit(X_train, y_train)
    score = accuracy_score(y_test, model.predict(X_test))
    
    print(f"     Config {i}: {score:.2%}")
    
    if score > best_score:
        best_score = score
        best_model = model
        best_name = f"RandomForest-{i}"

# Try Gradient Boosting
print("\n   Gradient Boosting:")
for i, config in enumerate(gb_configs, 1):
    model = GradientBoostingClassifier(
        random_state=42,
        **config
    )
    
    model.fit(X_train, y_train)
    score = accuracy_score(y_test, model.predict(X_test))
    
    print(f"     Config {i}: {score:.2%}")
    
    if score > best_score:
        best_score = score
        best_model = model
        best_name = f"GradientBoosting-{i}"

model = best_model
print(f"\n   ‚úì Best model: {best_name} with {best_score:.2%} accuracy")

# Evaluate
print("\n5Ô∏è‚É£ Evaluating model...")
y_pred_train = model.predict(X_train)
y_pred_test = model.predict(X_test)

train_acc = accuracy_score(y_train, y_pred_train)
test_acc = accuracy_score(y_test, y_pred_test)
test_f1 = f1_score(y_test, y_pred_test)
test_precision = precision_score(y_test, y_pred_test)
test_recall = recall_score(y_test, y_pred_test)

print(f"\n   Training Accuracy:   {train_acc:.2%}")
print(f"   Test Accuracy:       {test_acc:.2%}")
print(f"   Test Precision:      {test_precision:.2%}")
print(f"   Test Recall:         {test_recall:.2%}")
print(f"   Test F1 Score:       {test_f1:.2%}")

# Cross-validation
cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='f1')
print(f"\n   Cross-Validation F1: {cv_scores.mean():.2%} (+/- {cv_scores.std():.2%})")

# Feature importance
print("\n6Ô∏è‚É£ Feature Importance:")
feature_importance = sorted(
    zip(feature_cols, model.feature_importances_),
    key=lambda x: x[1],
    reverse=True
)
for feat, importance in feature_importance:
    print(f"   {feat:30s}: {importance:.3f}")

# Save model
print("\n7Ô∏è‚É£ Saving model...")
os.makedirs('models/saved', exist_ok=True)
joblib.dump(model, 'models/saved/challenge_recommender.pkl')

# Save feature names
with open('models/saved/recommender_features.txt', 'w') as f:
    f.write('\n'.join(feature_cols))

print("   ‚úì Saved models/saved/challenge_recommender.pkl")
print("   ‚úì Saved models/saved/recommender_features.txt")

# Save challenge metadata
challenge_meta_df = pd.DataFrame(challenge_types)
challenge_meta_df.to_csv('models/saved/challenge_metadata.csv', index=False)
print("   ‚úì Saved models/saved/challenge_metadata.csv")

# Final summary
print("\n" + "="*70)
print("‚úÖ CHALLENGE RECOMMENDER MODEL COMPLETE")
print("="*70)
print(f"\nüìä Final Metrics:")
print(f"   Test Accuracy:  {test_acc:.2%}")
print(f"   Test F1 Score:  {test_f1:.2%}")
print(f"   CV F1 Score:    {cv_scores.mean():.2%}")

if test_acc > 0.70 and test_f1 > 0.65:
    print(f"\n‚úÖ Model performance is GOOD for recommendations!")
elif test_acc > 0.60:
    print(f"\n‚ö†Ô∏è  Model performance is ACCEPTABLE")
else:
    print(f"\n‚ùå Model performance needs improvement")

print("="*70)
